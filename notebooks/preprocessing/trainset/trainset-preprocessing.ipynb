{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368c7be4",
   "metadata": {},
   "source": [
    "# Preprocessing of the raw training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d170e",
   "metadata": {},
   "source": [
    "## 1. Loading libraries, parameters and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ad05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddae1d.utils import despike_iterative, baseline_correction\n",
    "from ddae1d.paths import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef006a",
   "metadata": {},
   "source": [
    "### Loading parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5b965",
   "metadata": {},
   "source": [
    "Modify them in `./config.json` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de772525",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trainset_filename = config[\"raw_trainset_filename\"]\n",
    "\n",
    "trim_spectra = config[\"trim_spectra\"]\n",
    "spectral_ends = config[\"spectral_ends\"]\n",
    "\n",
    "apply_savgol = config[\"apply_savgol\"]\n",
    "savgol_params = config[\"savgol_params\"]\n",
    "\n",
    "apply_despike = config[\"apply_despike\"]\n",
    "n_jobs_despike = config[\"n_jobs_despike\"]\n",
    "despike_params = config[\"despike_params\"]\n",
    "\n",
    "apply_baseline_correction = config[\"apply_baseline_correction\"]\n",
    "polyfit_degree = config[\"polyfit_degree\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e9f07",
   "metadata": {},
   "source": [
    "### Loading raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57666b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trainset = np.load(PROJECT_ROOT / \"data\" / \"raw\" / \"trainset\" / raw_trainset_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbeaaa7",
   "metadata": {},
   "source": [
    "## 2. Trimming spectral ends and substracting offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6dad7b",
   "metadata": {},
   "source": [
    "### *If needed, trim the spectral ends to remove artefacts such as Rayleigh scattering*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0542682",
   "metadata": {},
   "source": [
    "Modify the values of `trim_spectra` and `spectral_ends` in `./config.json` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trim_spectra:\n",
    "    # Trim spectral ends\n",
    "    trainset = raw_trainset[:, :, spectral_ends[0]:spectral_ends[1]]\n",
    "else:\n",
    "    trainset = raw_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4272b3b",
   "metadata": {},
   "source": [
    "***It is necessary for the resulting number of spectral channels to be divisible by the highest possible power of 2, for the autoencoder architecture to work properly. Indeed, the encoding and decoding process involves multiple downsampling and upsampling steps, typically by a factor of 2. If the input size is not compatible with these operations, it can lead to issues such as mismatched dimensions during the reconstruction phase.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b7de6",
   "metadata": {},
   "source": [
    "### *If relevant, subtract an 'offset' baseline - common to the whole dataset. This should be done from the raw spectra before further preprocessing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac0791",
   "metadata": {},
   "source": [
    "#### Suggested method for computing the offset: Savitzky-Golay smoothed spectrum with lowest mean intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94557c65",
   "metadata": {},
   "source": [
    "*Tune Savitzky-Golay filter parameters in `config.json`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Savitzky-Golay smoothing is enabled, subtract a smoothed baseline from all spectra\n",
    "if apply_savgol:\n",
    "    # Find the index of the spectrum with the lowest mean intensity\n",
    "    lowest_mean_idx = tuple(int(arr[0]) for arr in np.where(np.nanmean(trainset, axis=2) == np.nanmean(trainset, axis=2).min()))\n",
    "    print(f\"Index of spectrum with lowest mean intensity: {lowest_mean_idx}\")\n",
    "\n",
    "    # Extract the spectrum with the lowest mean intensity\n",
    "    lowest_mean_spectrum = trainset[lowest_mean_idx]\n",
    "\n",
    "    # Show the Savitzky-Golay filter parameters\n",
    "    print(f\"Savitzky-Golay filter parameters: {savgol_params}\")\n",
    "\n",
    "    # Smooth the lowest mean intensity spectrum using Savitzky-Golay filter\n",
    "    smoothed_spectrum = savgol_filter(lowest_mean_spectrum, **savgol_params)\n",
    "\n",
    "    # Plot the original and smoothed spectrum for visual inspection\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(lowest_mean_spectrum, label=\"Original\", alpha=0.5)\n",
    "    plt.plot(smoothed_spectrum, label=\"Smoothed\", linewidth=2)\n",
    "    plt.xlabel(\"Spectral Channel\")\n",
    "    plt.ylabel(\"Intensity (a.u.)\")\n",
    "    plt.title(\"Lowest Mean Intensity Spectrum (Original vs Smoothed)\")\n",
    "    plt.xlim(0, len(lowest_mean_spectrum) - 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Subtract the smoothed baseline from all spectra in the training set\n",
    "    trainset_after_offset = trainset - smoothed_spectrum\n",
    "else:\n",
    "    trainset_after_offset = trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3198d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50ec71",
   "metadata": {},
   "source": [
    "## 3. Despiking (parallel processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f18a1b",
   "metadata": {},
   "source": [
    "Tune the number of parallel jobs: `n_jobs_despike` in `config.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44798b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def despike_task(point, repetition):\n",
    "    despiked_spectrum, spikes_spectrum = despike_iterative(\n",
    "        trainset_after_offset[point, repetition, :],\n",
    "        **despike_params\n",
    "    )\n",
    "    return (point, repetition, despiked_spectrum, spikes_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_despike:\n",
    "    print(f\"Number of jobs for parallel despiking: {n_jobs_despike % (os.cpu_count() + 1)}\")\n",
    "    spikes = np.zeros_like(trainset_after_offset)\n",
    "    trainset_after_despike = np.zeros_like(trainset_after_offset)\n",
    "    print(\"Starting parallel despiking of final map...\")\n",
    "    print(f\"Total spectra to despike (tasks to do): {trainset_after_offset.shape[0]}\")\n",
    "    results = Parallel(n_jobs=n_jobs_despike, verbose=1)(\n",
    "        delayed(despike_task)(point, repetition)\n",
    "        for point in range(trainset_after_offset.shape[0])\n",
    "        for repetition in range(trainset_after_offset.shape[1])\n",
    "    )\n",
    "    for point, repetition, despiked_spectrum, spikes_spectrum in results:\n",
    "        trainset_after_despike[point, repetition, :] = despiked_spectrum\n",
    "        spikes[point, repetition, :] = spikes_spectrum\n",
    "    del results\n",
    "    nonzero_indices = np.argwhere(np.any(spikes != 0, axis=2)).squeeze()\n",
    "    percentage_nonzero = len(nonzero_indices) / (trainset_after_despike.shape[0] * trainset_after_despike.shape[1]) * 100\n",
    "    print(f\"Percentage of spectra despiked: {percentage_nonzero:.2f}%\")\n",
    "    print(\"Number of spectra despiked:\", len(nonzero_indices))\n",
    "else:\n",
    "    trainset_after_despike = trainset_after_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainset_after_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819ccd4",
   "metadata": {},
   "source": [
    "### Plot 20 random examples of despiked spectra vs removed spikes\n",
    "Verify that despiking is effective and does not remove relevant signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_despike:\n",
    "    n_plot = min(20, len(nonzero_indices))\n",
    "    selected_indices = nonzero_indices[np.random.choice(len(nonzero_indices), n_plot, replace=False)]\n",
    "\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(20, 12), sharex=True, sharey=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, (point, repetition) in zip(axes, selected_indices):\n",
    "        ax.plot(trainset_after_despike[point, repetition], label='Despiked', zorder=1)\n",
    "        ax.plot((trainset_after_despike + spikes)[point, repetition], label='Removed Spikes', zorder=0)\n",
    "        ax.set_title(f'Point {point}, Rep {repetition}')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66aefe0",
   "metadata": {},
   "source": [
    "## 4. Baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_baseline_correction:\n",
    "    trainset_after_baseline = baseline_correction(trainset_after_despike, polyfit_degree)\n",
    "else:\n",
    "    trainset_after_baseline = trainset_after_despike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainset_after_despike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af1b2c",
   "metadata": {},
   "source": [
    "## 5. Saving preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea36b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(PROJECT_ROOT / \"data\" / \"preprocessed\" / \"trainset\" / \"noisy.npy\", trainset_after_baseline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ddae-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
